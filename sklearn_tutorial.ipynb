{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Develop RNN Models with Keras\n",
    "In this tutorial we go over creating different machine learning models using scikit-learn library. We will experiment with a supervised regression problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Jupyter Environment\n",
    "Let's start by getting familiar with jupyter environment and some simple tricks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this cell for some simple commands.\n",
    "# Press ctrl+enter to execute a cell\n",
    "# Use shift+enter to execute a cell and move on to the next cell\n",
    "a = 1\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Import necessary packages\n",
    "Now that we are familiart with the Jupyter environment, let's continue by importing some necessary packages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Download a sample dataset\n",
    "Then we will download a sample data set. The dataset we will be using is \"Appliances Energy Prediction Dataset\".\n",
    "\n",
    "Here is more information about his data set.\n",
    "https://archive.ics.uci.edu/ml/datasets/Appliances+energy+prediction\n",
    "\n",
    "Attribute Information:\n",
    "\n",
    "date time year-month-day hour:minute:second<br>\n",
    "Appliances, energy use in Wh<br>\n",
    "lights, energy use of light fixtures in the house in Wh<br>\n",
    "T1, Temperature in kitchen area, in Celsius<br>\n",
    "RH_1, Humidity in kitchen area, in %<br>\n",
    "T2, Temperature in living room area, in Celsius<br>\n",
    "RH_2, Humidity in living room area, in %<br>\n",
    "T3, Temperature in laundry room area<br>\n",
    "RH_3, Humidity in laundry room area, in %<br>\n",
    "T4, Temperature in office room, in Celsius<br>\n",
    "RH_4, Humidity in office room, in %<br>\n",
    "T5, Temperature in bathroom, in Celsius<br>\n",
    "RH_5, Humidity in bathroom, in %<br>\n",
    "T6, Temperature outside the building (north side), in Celsius<br>\n",
    "RH_6, Humidity outside the building (north side), in %<br>\n",
    "T7, Temperature in ironing room , in Celsius<br>\n",
    "RH_7, Humidity in ironing room, in %<br>\n",
    "T8, Temperature in teenager room 2, in Celsius<br>\n",
    "RH_8, Humidity in teenager room 2, in %<br>\n",
    "T9, Temperature in parents room, in Celsius<br>\n",
    "RH_9, Humidity in parents room, in %<br>\n",
    "To, Temperature outside (from Chievres weather station), in Celsius<br>\n",
    "Pressure (from Chievres weather station), in mm Hg<br>\n",
    "RH_out, Humidity outside (from Chievres weather station), in %<br>\n",
    "Wind speed (from Chievres weather station), in m/s<br>\n",
    "Visibility (from Chievres weather station), in km<br>\n",
    "Tdewpoint (from Chievres weather station), Â°C<br>\n",
    "rv1, Random variable 1, nondimensional<br>\n",
    "rv2, Random variable 2, nondimensional<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's download a sample dataset as a pandas dataframe\n",
    "df = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/00374/energydata_complete.csv\")\n",
    "\n",
    "# Print a few rows of the data, complete the following line:\n",
    "df..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many samples do we have in this data set? Complete the following line\n",
    "print(\"Total number of samples: \", df...)\n",
    "\n",
    "# Let's visualize some of the data\n",
    "n_samples = 1000\n",
    "feature_name = \"T9\"\n",
    "target_name = \"T2\"\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "ax2 = ax1.twinx()\n",
    "ax1.plot(df[feature_name].values[:n_samples], 'b-')\n",
    "ax2.plot(df[target_name].values[:n_samples], 'g-')\n",
    "ax1.set_xlabel('Samples')\n",
    "ax1.set_ylabel(feature_name, color='b')\n",
    "ax2.set_ylabel(target_name, color='g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Create input and output\n",
    "We should extract our inputs and outputs from the dataframe. We will use the living room temperature as the target. To further speed up training, we will use a subset of all the available features.\n",
    "We will also exclude some of other temperatures as they might be very correlated with the living room temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_use = [\"lights\", # energy use of light fixtures in the house in Wh\n",
    "                   \"T4\", # Temperature in office room, in Celsius\n",
    "                   \"T6\", # Temperature outside the building (north side), in Celsius\n",
    "                   \"T7\", # Temperature in ironing room , in Celsius\n",
    "                   \"T8\", # Temperature in teenager room 2, in Celsius\n",
    "                   \"T9\", # Temperature in parents room, in Celsius\n",
    "                   \"T_out\", # Temperature outside (from Chievres weather station), in Celsius\n",
    "                   \"Press_mm_hg\", # (from Chievres weather station), in mm Hg\n",
    "                   \"RH_out\", # Humidity outside (from Chievres weather station), in %\n",
    "                   \"Windspeed\", # Windspeed (from Chievres weather station), in m/s\n",
    "                   \"Visibility\", # Visibility (from Chievres weather station), in km\n",
    "                   \"Tdewpoint\" # Dew point (from Chievres weather station), Â°C\n",
    "                  ]\n",
    "# Grab a portion of the data to make training and testing faster\n",
    "samples = 6000\n",
    "data = df[features_to_use].values[:samples, :]\n",
    "target = df[target_name].values[:samples]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Split the data into train, test, validation\n",
    "For training a model and evaluating the performance, we devide the model into train, validation, and test sets. \n",
    "\n",
    "We will use the training and validation set to design the architecture, train the model, and optimize the hyperparameters. Then use the test set to report the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Scikit-learn data splitting functions, complete the following line\n",
    "from sklearn.model_selection import ...\n",
    "\n",
    "# Determine train test splits\n",
    "test_ratio = 0.2\n",
    "\n",
    "# Split the data into training and testing\n",
    "x_trn, x_tst, y_trn, y_tst = train_test_split(data, target, test_size=test_ratio, shuffle=True, random_state=0)\n",
    "\n",
    "# Split the training data into training and validation\n",
    "x_trn, x_vld, y_trn, y_vld = train_test_split(x_trn, y_trn, test_size=test_ratio, shuffle=True, random_state=0)\n",
    "\n",
    "# Print how many samples we have in each set, complete the following lines\n",
    "print(\"Number of samples in the training set: \", ...)\n",
    "print(\"Number of samples in the validation set: \", ...)\n",
    "print(\"Number of samples in the test set: \", ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Normalize the Data\n",
    "Most of the time, we should \"prepare\" our data and make it ready for model development. The preperation might include dealing with missing data, normalization, etc. \n",
    "\n",
    "Here, we will normalize the data. Can you explain why we need to normalize the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data, complete the following lines\n",
    "mean = x_trn...\n",
    "std = x_trn...\n",
    "x_trn = ...\n",
    "x_vld = ...\n",
    "x_tst = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Train ML models\n",
    "Now that we have prepared the data and split it into train, validation, and test sets, we can train ML models.\n",
    "\n",
    "Several different models are available from scikit-learn. We will start with a simple linear regression model. But, we will also look at other regressors as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the model from scikit-learn package.\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Create an instance of the model, complete the following line\n",
    "reg = ...\n",
    "\n",
    "# Train the model, complete the following line\n",
    "reg.fit(..., ...)\n",
    "\n",
    "# Calculate the training error and print, completet the following lines\n",
    "y_trn_prd = reg.predict(x_trn)\n",
    "trn_error = np.mean(np.abs(... - ...))\n",
    "print(...)\n",
    "\n",
    "# Calculate the validation error, complete the following lines\n",
    "y_vld_prd = reg.predict(...)\n",
    "vld_error = np.mean(np.abs(... - ...))\n",
    "print(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Testing the Model\n",
    "Once we have trained the model, and have finalized the parameters, we can see how it performs on out test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once we we have decided on the parameters, we can print the test error\n",
    "y_tst_prd = reg.predict(x_tst)\n",
    "tst_error = np.mean(np.abs(y_tst - y_tst_prd))\n",
    "print(tst_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making prediciton on a new data sample\n",
    "target_prd = reg.predict((data-mean)/std)\n",
    "samples_to_plot = 1000\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(target[:samples_to_plot])\n",
    "plt.plot(target_prd[:samples_to_plot], \"--\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also take a look at the feature_importance. It basically shows how much each feature contributes to the final\n",
    "# prediction. \n",
    "feature_imp_df = pd.DataFrame(data={\"Name\": features_to_use, \"Importance\": reg.feature_importances_})\n",
    "feature_imp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What to try next\n",
    "You can read about the following topics if you like to further pursue this topic:\n",
    "- Try the model without normalization and see if it affects the result\n",
    "- Read about and try other types of regressors in scikitlearn (SVR, GradientBoostingRegressor, ExtraTreesRegressor, etc.)\n",
    "- Read and try neural network based approaches (ANN, RNN, CNN)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
